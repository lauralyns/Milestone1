{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc6f355-8f66-403c-8b72-80ee5dd876aa",
   "metadata": {},
   "source": [
    "### SLR Data Preprocessing\n",
    "Creates a csv file that has all the census tracts that will be impacted by a given Sea Level Rise scenario.<br>\n",
    "create_slr_csv() has a print statement that updates progress whenever a file is added to the cvs. This can be commented out if wanted.\n",
    "#### Required variables can be set before invoking with %run:\n",
    "<strong>slr_rise</strong><br>\n",
    "How many feet of sea level rise (from 1 to 10ft)<br>\n",
    "<strong>SLRs</strong><br>\n",
    "List of all file extensions for SLR files to download - (Dynamic JavaScript so didn't scrape)</strong><br>\n",
    "<strong>fips_dict</strong><br>\n",
    "Dictionary of State-FIPS codes for all states in coastal contiguous US<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8d971a8-269d-4b0a-b4f0-81bfb5d12147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#If running file seperate from Analysis.ipynb, might need to pip install geopandas\n",
    "! pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c43f29ac-7cf8-4889-9e0b-e4f0f911a203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4146690-0182-4808-9572-e5f4db8164b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Setting variables to default values if not set before using %run to run file\n",
    "\n",
    "try:\n",
    "    slr_feet\n",
    "except:\n",
    "    slr_feet = '1'\n",
    "\n",
    "try:\n",
    "    SLRs\n",
    "except:  \n",
    "    SLRs = ['AL/AL','CA/CA_EKA','CA/CA_LOX','CA/CA_MTR','CA/CA_SGX','CA/CA_ChannelIslands','CA/CA_Catalina',\n",
    "        'NewEngland/CT','DE/DE','DC/DC','FL/FL_Pan_West','FL/FL_Pan_East','FL/FL_West_3','FL/FL_West_2',\n",
    "        'FL/FL_West_1','FL/FL_SW','FL/FL_Keys','FL/FL_SE','FL/FL_East_1','FL/FL_East_2','FL/FL_NE',\n",
    "        'GA/GA_South','GA/GA_North','LA/LA_LP','LA/LA_Delta','LA/LA_Central','LA/LA_CentralEast',\n",
    "        'LA/LA_CentralNorth','LA/LA_West','NewEngland/ME_East','NewEngland/ME_West','MD/MD_Southeast',\n",
    "        'MD/MD_East','MD/MD_North','MD/MD_West','MD/MD_Southwest','NewEngland/MA','MS/MS','NewEngland/NH',\n",
    "        'NJ/NJ_Northern','NJ/NJ_Middle','NJ/NJ_Southern','NY/NY_Hudson','NY/NY_Metro','NY/NY_Suffolk',\n",
    "        'NC/NC_Northern','NC/NC_Middle1','NC/NC_Middle2','NC/NC_Southern1','NC/NC_Southern2','OR/OR_MFR',\n",
    "        'OR/OR_PQR','PA/PA','NewEngland/RI','SC/SC_North','SC/SC_Central','SC/SC_South','TX/TX_North1',\n",
    "        'TX/TX_North2','TX/TX_Central','TX/TX_South1','TX/TX_South2','VA/VA_EasternShore','VA/VA_Northern',\n",
    "        'VA/VA_Middle','VA/VA_Southern','WA/WA_PQR','WA/WA_SEW','WA/WA_PugetNW','WA/WA_PugetSW']\n",
    "\n",
    "try:\n",
    "    fips_dict\n",
    "except: \n",
    "    fips_dict = {'AL':'01','CA':'06','CT':'09','DE':'10','DC':'11','FL':'12','GA':'13','LA':'22','ME':'23',\n",
    "             'MD':'24','MA':'25','MS':'28','NH':'33','NJ':'34','NY':'36','NC':'37','OR':'41','PA':'42','RI':'44',\n",
    "             'SC':'45','TX':'48','VA':'51','WA':'53'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06b7ad6b-4bb3-4d4e-8150-449332c2d5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Checking if SLR.csv file already exists, and creating it if it doesn't "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3098fe04-7cce-45fa-ac0b-5e66778bdd05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -e \"data/SLR.csv\" ]; then\n",
    "    echo 'SLRs,STATEFP,COUNTYFP,TRACTCE,census_tract,SLR_ft' >> data/SLR.csv\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2faa8c3c-875d-45e8-8616-192dff0ff52a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_slr_layer(slr, folder, slr_feet):\n",
    "    '''Input is an slr file stem for folder of .gdbtable files, and level of slr_feet rise\n",
    "    output is the slr file name corresponding to the slr_feet parameter layer'''\n",
    "    file_list = !ls {folder}\n",
    "    for file in file_list:\n",
    "        if fiona.listlayers('{}/{}'.format(folder, file))[0].endswith('slr_{}ft'.format(slr_feet)):\n",
    "            return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "241ee32d-2c05-40b0-82bb-a47fcb6d51ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_slr_df(slr, slr_feet):\n",
    "    '''Input: slr file stem and level of slr_feet rise\n",
    "        Output: a dataframe made from the geospatial layer corresponding to the slr_feet rise parameter'''\n",
    "    try:\n",
    "        folder = 'data/SLR_ShapeFiles/{}_slr_final_dist.gdb'.format(slr)\n",
    "        slr_file = find_slr_layer(slr, folder, slr_feet)\n",
    "        slr_df = gpd.read_file('{}/{}'.format(folder, slr_file))\n",
    "    except:\n",
    "        try:\n",
    "            #A number of files are not separate .gdbtable files, but .gpkg files where each slr scenario is a layer\n",
    "            slr_df = gpd.read_file('data/SLR_ShapeFiles/{}_slr_final_dist.gpkg'.format(slr), \n",
    "            layer='{}_slr_{}_0ft'.format(slr, slr_feet))\n",
    "            \n",
    "        #Handling exceptions for 2 files that do not adhere to same file formatting\n",
    "        except:\n",
    "            try:\n",
    "                slr_df = gpd.read_file('data/SLR_ShapeFiles/{}_slr_final_dist.gpkg'.format(slr), \n",
    "                layer='FL_East1_slr_{}_0ft'.format(slr_feet))\n",
    "            except:\n",
    "                folder = 'data/SLR_ShapeFiles/LA_LakePontchartrain_slr_final_dist_polys.gdb'\n",
    "                slr_file = find_slr_layer(slr, folder, slr_feet)\n",
    "                slr_df = gpd.read_file('{}/{}'.format(folder, slr_file))\n",
    "                \n",
    "    return slr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3e74a21-69d2-478d-b2fd-07350e70a6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_intersecting_df(slr_df, census_df, slr, slr_feet):\n",
    "    '''Input: SLR geospatial dataframe and Census tract geospatial dataframe\n",
    "    Output: New temp_df containing all the geospatial locations that intersect - \n",
    "    that is, the census tracts that are affected by the specific SLR scenario.'''\n",
    "    \n",
    "    #Saving index so can reference which tract 'shapes' intersect\n",
    "    census_df['savedindex'] = census_df.index \n",
    "    intersecting = slr_df.sjoin(census_df, how='inner')['savedindex']\n",
    "        \n",
    "    #Creating new DF\n",
    "    temp_df = census_df[census_df.savedindex.isin(intersecting)][['STATEFP','COUNTYFP','TRACTCE']]\n",
    "    temp_df['SLRs'] = slr\n",
    "    temp_df['census_tract']= temp_df.apply(lambda x: x['STATEFP']+x['COUNTYFP']+x['TRACTCE'], axis=1)\n",
    "    temp_df['SLR_ft'] = slr_feet\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9192e897-14af-4e63-918b-7f9a818c11be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_slr_csv(slr_feet, SLRs, fips_dict):\n",
    "    '''Input: slr_feet - a specific sea level rise scenario, \n",
    "        SLRs - list of file stems from NOAA website for county areas to use\n",
    "        fips_dict - dictionary of state-FIPS numbers for states to use\n",
    "       Output: saves a .csv file with all the census tracts that are effected by slr scenario'''\n",
    "    SLR_Census_df = pd.read_csv('data/SLR.csv')\n",
    "    \n",
    "    for stem in SLRs:\n",
    "        slr = stem.split('/')[1]\n",
    "        state = slr[:2]\n",
    "        #Pass if already in CSV - this way can re-run if process fails or times out\n",
    "        if slr in SLR_Census_df[SLR_Census_df.SLR_ft == int(slr_feet)].SLRs.unique():\n",
    "            pass\n",
    "        #Otherwise create geopandas df for specified slr scenario\n",
    "        else:\n",
    "            slr_df = create_slr_df(slr,slr_feet)\n",
    "            census_df = gpd.read_file(\"data/Census_ShapeFiles/tl_rd22_{}_tract.shp\".format(fips_dict[state]))\n",
    "            temp_df = create_intersecting_df(slr_df, census_df, slr, slr_feet)\n",
    "        \n",
    "            #Updating SLR_Census df and saving to csv\n",
    "            SLR_Census_df = pd.concat([SLR_Census_df, temp_df], axis=0)\n",
    "            SLR_Census_df.to_csv('data/SLR.csv', index=False)\n",
    "            \n",
    "            #Uncomment for print statements to track file download progress.\n",
    "            print(slr, 'added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0d7df48-3a59-4c9d-a400-91d2fc32bd73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_slr_csv(slr_feet, SLRs, fips_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21576006-e4ac-414e-a5ca-63e4e78b756c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
