{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4697d7f9",
   "metadata": {},
   "source": [
    "### HMDA Data Preprocessing\n",
    "This file covers initial data loading and cleaning for the HMDA dataset. \n",
    "\n",
    "The primary dataset for this project is residential mortgage application data released by the FFIEC per the Home Mortgage Disclosure Act, hereafter referred to as the HDMA dataset (see reference 2). Data is available from 2018 to 2022 which will serve as the time period for our analysis.\n",
    "\n",
    "This dataset covers mortgage application for single family properties, multifamily properties and a smaller percentage of other real estate. A variety of supporting information is provided for each mortgage such as the action taken on that application, e.g., approved, denied, etc., FIPS codes for the property (state and county), mortgage type, loan amount and appraised property values, loan to value ratios, debt ratios, etc., as well as general social demographic details on the borrower. \n",
    "\n",
    "The data for our analysis covers 2018 to 2022 and the file for each year is quite large (~1GB), which is making consolidating the data quite challenging given local computing resource constraints. To circumvent this issue, the datafile for each year is being cleaned individually (see details below) and only the aggregate details need for each county are consolidated instead of consolidating at the application level. \n",
    "\n",
    "#### Details on data cleaning:\n",
    "* This project will focus on the risk of flooding in areas expected to experience rising sea levels and hence will focus on the coastal counties of the United States (see reference [1]). As a first step in our data preparation, all non coastal properties  are removed from the dataset (Step1).\n",
    "\n",
    "* The HMDA dataset contains single family homes, mult family homes as well as some rural properties. For this project, we are primarily interested in the property values for single family homes; multi family homes and other types of real estate are excluded (Step2).\n",
    "\n",
    "* Our main variable of interest is the property_value. therefore any records with unusable values for this feature are excluded\n",
    "\n",
    "* Since the HDMA dataset is at the mortgage application level (as opposed to the issued mortage level), it contains data on denied applications or applications that were approved but where the loans were not issued for some reason. We exclude all applications where there may be concerns about data completeness (see data dictionary for relevant codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ff5048e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "959ecc40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_county_FIPS</th>\n",
       "      <th>county_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>ocean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>45053</td>\n",
       "      <td>Jasper</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>36005</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>New York</td>\n",
       "      <td>Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>23023</td>\n",
       "      <td>Sagadahoc</td>\n",
       "      <td>Maine</td>\n",
       "      <td>Atlantic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    state_county_FIPS county_name      state_name     ocean\n",
       "198             45053      Jasper  South Carolina  Atlantic\n",
       "155             36005       Bronx        New York  Atlantic\n",
       "114             23023   Sagadahoc           Maine  Atlantic"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def coastal_counties(path = \"\"):\n",
    "    \"\"\"\n",
    "    Description: function to load the file of coastal counties. Note for this analysis,  only contiguous US territories \n",
    "    are considered. So Hawaii will be dropped\n",
    "    I/P: Optional file path. See [1] in references for original source\n",
    "    O/P:Series of coastal counties\n",
    "    \"\"\"\n",
    "    cc = pd.read_excel(path + \"Coastal/coastline-counties-list.xlsx\", usecols = [0, 3, 4, 5], \n",
    "                       skiprows = 3, nrows = 255, dtype = str)\n",
    "    cc.columns = [\"state_county_FIPS\", \"county_name\", \"state_name\", \"ocean\"]\n",
    "    cc = cc[cc.state_name != \"Hawaii\"] \n",
    "#     cc.drop(labels = [\"state\"], axis = 1, inplace = True)\n",
    "    \n",
    "    #dropping 'county' from county names so we can match fema data\n",
    "    cc[\"county_name\"] = [name[:-7] if \" County\" in name else name for name in list(cc[\"county_name\"])]\n",
    "\n",
    "    return cc\n",
    "\n",
    "ccounties = coastal_counties('data/')\n",
    "ccounties.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d41f97e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hmda_datacleaning(df, ccounties):\n",
    "    \n",
    "    \"\"\" \n",
    "    Description: this function cleans the HMDA dataset to keep only the data needed for further analysis.\n",
    "    I/P: original dataframe\n",
    "    O/P: cleaned dataframe\n",
    "    \"\"\"\n",
    "    #Step 1: COASTAL PROPERTIES \n",
    "    #to reduce the data size, all non-coastal counties are removed per reference [1] and only  Note for this analysis,\n",
    "    #only contiguous US territories are considered; Hawaii, Puerto Rico, US Virgin Islands and other such territories\n",
    "    #are not included in the analysis. Additionally, counties with great lakes coasts are not considerd since the focus\n",
    "    #is on sea level rising. \n",
    "    df = df[df.county_code.isin(ccounties.state_county_FIPS)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Step 2: SINGLE FAMILY HOMES\n",
    "    #Keeping only single family homes and removing multi-family homes and rural properties (loan_type = 4; see reference 3):\n",
    "    #<why are we removing multi-families\n",
    "    df = df[df.loan_type != 4]\n",
    "    df = df[df.derived_dwelling_category.apply(lambda x: 'Single Family' in x)]\n",
    "\n",
    "    \n",
    "    \n",
    "    #Step 3: NON NUMERIC/MISSING PROPERTY VALUE\n",
    "    #Removing any records with non numeric property values since those do not provide useful info\n",
    "    df[\"property_value\"] = pd.to_numeric(df[\"property_value\"], errors='coerce')\n",
    "    df.dropna(subset = \"property_value\", inplace = True)\n",
    "    \n",
    "   \n",
    "\n",
    "    #Step 3: \n",
    "    #(A)we exclude those cases where the application was withdrawn by the applicant or where the file was\n",
    "    #closed for incompleteness as we cannot be certain that the data for this record are complete and accurate\n",
    "    df = df[~df.action_taken.isin([4,5])]\n",
    "    \n",
    "    \n",
    "    #(B) For the applications that were denied, we exclude them if the denial reason was incomplete documentation\n",
    "    df = df[~(df.action_taken.isin([3,7])) | (\n",
    "                                             (df.action_taken.isin([3,7])) & (\n",
    "                                                                            (~df.denial_reason_1.isin([6,7])) &\n",
    "                                                                            (~df.denial_reason_2.isin([6,7])) &\n",
    "                                                                            (~df.denial_reason_3.isin([6,7])) &\n",
    "                                                                            (~df.denial_reason_4.isin([6,7])))\n",
    "                                             )]\n",
    "    denial_reason_cols = [\"denial_reason_1\", \"denial_reason_2\",\"denial_reason_3\",\"denial_reason_4\"]\n",
    "    df.drop(labels = denial_reason_cols, axis = 1, inplace = True)\n",
    "    \n",
    "   \n",
    "#     #removed - we are no longer reading in these columns\n",
    "#     #Step 4: similarly, analysis of race and other demographic details is beyong the scope of this project so we drop \n",
    "#     #those columns\n",
    "#     demographic_cols = []\n",
    "#     for col in df.columns:\n",
    "#         if 'ethnicity' in col or 'race' in col or 'sex' in col or 'age' in col:\n",
    "#             demographic_cols.append(col) #the number of cols in our dataset should drop a lot after this\n",
    "#     df.drop(labels = demographic_cols, axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     #Step 5: since the focus of this project is conventional mortgages and associated home prices,\n",
    "#     #we exclude reverse mortgages and other lines of credit  \n",
    "#     df = df[(df[\"reverse_mortgage\"] == 2) & (df[\"open_end_line_of_credit\"] == 2)]\n",
    "#     df.drop(labels = [\"reverse_mortgage\",\"open_end_line_of_credit\"], axis = 1, inplace = True)\n",
    "    \n",
    "   \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef25890f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hmda_datasetcreation(year, path = \"\"):\n",
    "    \"\"\" \n",
    "    Description: this function first loads the dataset for each year and then calls the cleaning function to reduce\n",
    "    this large dataset to only the needed dataset (coastal counties and other cleaning). Finally, this cleaned dataset\n",
    "    for each year is concatenated to create the full dataset\n",
    "    \n",
    "    I/P: Optional file path. See [1] in references for original source\n",
    "    O/P: final consolidatd dataset\n",
    "    \"\"\"\n",
    "    #data loading\n",
    "    df_raw = pd.read_csv(path + \"HMDA/\"+ str(year) + \".zip\", compression = \"zip\", \n",
    "                             dtype={'county_code': object, \"census_tract\" : object, 'derived_msa_md': object},\n",
    "                             usecols = ['activity_year', 'derived_msa_md', 'county_code','census_tract', \n",
    "                                        'loan_type','action_taken', 'property_value', 'derived_dwelling_category',\n",
    "                                        'reverse_mortgage','open_end_line_of_credit',\n",
    "                                        'denial_reason_1', 'denial_reason_2', 'denial_reason_3', 'denial_reason_4'])\n",
    "    \n",
    "    #data cleaning\n",
    "    df = hmda_datacleaning(df_raw, ccounties)\n",
    "    \n",
    "    \n",
    "#     #formats get messed up so using pickle instead\n",
    "#     #writing file to disk as csv\n",
    "#     filename = 'cleaned_' + str(year)\n",
    "#     compression_options = dict(method='zip', archive_name=f'{filename}.csv')\n",
    "#     df.to_csv(f'{filename}.zip', compression=compression_options)\n",
    "    \n",
    "    \n",
    "    #writing file to disk as a pickle file to preserve formats\n",
    "    filename = 'cleaned_' + str(year)\n",
    "    compression_options = dict(method='zip', archive_name=f'HMDA/{filename}.pkl')\n",
    "    df.to_pickle(f'data/HMDA/{filename}.zip', compression=compression_options)\n",
    " \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b88a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "years = np.arange(2018, 2023)\n",
    "for year in years:\n",
    "    hmda_datasetcreation(year,'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff779f96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hmda_consolidation_aggregation(path = \"\"):\n",
    "    \"\"\" \n",
    "    Description: Because the raw files were so large, directly consolidating the datasets resulted in memory issues.\n",
    "    This function first calculates the median property values by state/county/censustract FIPS codes and then aggregates\n",
    "    the data to reduce file size. The aggregated data is written to disk for reuse\n",
    "    \n",
    "    I/P: Optional file path\n",
    "    O/P: final aggregated and consolidatd dataset 2019 to 2022\n",
    "    \"\"\"\n",
    "    \n",
    "    #placeholder for aggregated results\n",
    "    results_full = pd.DataFrame() #columns = ['county_code', 'property_value', 'year'])  \n",
    "    \n",
    "    years = np.arange(2018, 2023) \n",
    "    for year in years:\n",
    "        \n",
    "        #data loading\n",
    "        df = pd.read_pickle(path + \"HMDA/\" + \"cleaned_\" + str(year) + \".zip\", compression = \"zip\")  #column types are being preserved\n",
    "\n",
    "        #aggregation\n",
    "        results = df.groupby(['activity_year','county_code','census_tract'], as_index = False).agg({\"property_value\":\"median\"})\n",
    "        \n",
    "        #consolidation        \n",
    "        #results_full = results_full.append(results, ignore_index = True) #append decpriciated\n",
    "        results_full = pd.concat([results_full, results], axis=0)\n",
    "    \n",
    "    #merging with county file for county names\n",
    "    results_full = results_full.merge(ccounties, left_on = \"county_code\", right_on = \"state_county_FIPS\")\n",
    "#     results_full[\"ID\"] = results_full['county_code'] + \"_\" + results_full['census_tract']\n",
    "    \n",
    "    \n",
    "    #for some census_tracts, we do not have data for all five years which would make time series based comparison\n",
    "    #impossible. dropping these values\n",
    "#     _ = results_full.groupby('ID').size()\n",
    "    _ = results_full.groupby('census_tract').size()\n",
    "    _ = _[_ == 5] #meaning we have 5years of data\n",
    "    census_tracts_w_full_data = list(_.index)\n",
    "    results_full = results_full[results_full.census_tract.isin(census_tracts_w_full_data)]\n",
    "    \n",
    "    \n",
    "    #writing to disk for easy access\n",
    "    compression_options = dict(method='zip', archive_name='results_full.pkl')\n",
    "    results_full.to_pickle('data/results_full.zip', compression=compression_options)\n",
    "    \n",
    "    return results_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a4c1d-058b-48e5-9161-879a313b5816",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmda_consolidation_aggregation('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba67be01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df = hmda_consolidation_aggregation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cef58e65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_year</th>\n",
       "      <th>county_code</th>\n",
       "      <th>census_tract</th>\n",
       "      <th>property_value</th>\n",
       "      <th>state_county_FIPS</th>\n",
       "      <th>county_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>ocean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>01003</td>\n",
       "      <td>01003010100</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Gulf of Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>01003</td>\n",
       "      <td>01003010200</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Gulf of Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>01003</td>\n",
       "      <td>01003010300</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Gulf of Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>01003</td>\n",
       "      <td>01003010400</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Gulf of Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>01003</td>\n",
       "      <td>01003010500</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Gulf of Mexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity_year county_code census_tract  property_value state_county_FIPS   \n",
       "0           2018       01003  01003010100        175000.0             01003  \\\n",
       "1           2018       01003  01003010200        145000.0             01003   \n",
       "2           2018       01003  01003010300        225000.0             01003   \n",
       "3           2018       01003  01003010400        185000.0             01003   \n",
       "4           2018       01003  01003010500        145000.0             01003   \n",
       "\n",
       "  county_name state_name           ocean  \n",
       "0     Baldwin    Alabama  Gulf of Mexico  \n",
       "1     Baldwin    Alabama  Gulf of Mexico  \n",
       "2     Baldwin    Alabama  Gulf of Mexico  \n",
       "3     Baldwin    Alabama  Gulf of Mexico  \n",
       "4     Baldwin    Alabama  Gulf of Mexico  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb615202-c22b-47d6-9439-1485ddc1104e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
