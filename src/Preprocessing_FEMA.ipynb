{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5963566e-7972-49a2-a3fc-17dd999c656a",
   "metadata": {},
   "source": [
    "### FEMA Data Preprocessing\n",
    "This file covers initial data loading and cleaning for the FEMA dataset. \n",
    "\n",
    "This FEMA dataset is used to find census tracts that are in areas FEMA has designated as high risk flood zones.\n",
    "Because this original datafile is over 500mb in size, we have reduced the file to only include census tracts in coastal counties,\n",
    "and with 'Very High', and 'Relatively High' flood risk levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a5f225-47c4-4a90-8777-549cbad126b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd45e7bf-a61f-45dd-81b3-910b6098a0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_county_FIPS</th>\n",
       "      <th>county_name</th>\n",
       "      <th>state_name</th>\n",
       "      <th>ocean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>12035</td>\n",
       "      <td>Flagler</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>51131</td>\n",
       "      <td>Northampton</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>34013</td>\n",
       "      <td>Essex</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Atlantic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    state_county_FIPS  county_name  state_name     ocean\n",
       "62              12035      Flagler     Florida  Atlantic\n",
       "226             51131  Northampton    Virginia  Atlantic\n",
       "148             34013        Essex  New Jersey  Atlantic"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def coastal_counties(path = \"\"):\n",
    "    \"\"\"\n",
    "    Description: function to load the file of coastal counties. Note for this analysis,  \n",
    "    only contiguous US territories are considered. So Hawaii will be dropped\n",
    "    I/P: Optional file path. See [1] in references for original source\n",
    "    O/P:Series of coastal counties\n",
    "    \"\"\"\n",
    "    cc = pd.read_excel(path + \"Coastal/coastline-counties-list.xlsx\", usecols = [0, 3, 4, 5], \n",
    "                       skiprows = 3, nrows = 255, dtype = str)\n",
    "    cc.columns = [\"state_county_FIPS\", \"county_name\", \"state_name\", \"ocean\"]\n",
    "    cc = cc[cc.state_name != \"Hawaii\"] \n",
    "#     cc.drop(labels = [\"state\"], axis = 1, inplace = True)\n",
    "    \n",
    "    #dropping 'county' from county names so we can match fema data\n",
    "    cc[\"county_name\"] = [name[:-7] if \" County\" in name else name for name in list(cc[\"county_name\"])]\n",
    "\n",
    "    return cc\n",
    "\n",
    "ccounties = coastal_counties('data/')\n",
    "ccounties.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d595f5f1-9daf-4e76-a7ec-984d3ad08f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fema_datacleaning(ccounties):\n",
    "    \n",
    "    \"\"\" \n",
    "    Description: this function cleans the FEMA dataset to keeps only the data needed for further analysis.\n",
    "    I/P: original dataframe\n",
    "    O/P: cleaned dataframe\n",
    "    \"\"\"\n",
    "        \n",
    "    #data loading\n",
    "    fema = pd.read_csv(\"data/FEMA/NRI_Table_CensusTracts.csv\",\n",
    "                             dtype={'STCOFIPS': object, \"TRACT\" : object},\n",
    "                             usecols = ['STCOFIPS', 'TRACT', 'CFLD_RISKR', 'STATE', 'COUNTY'])\n",
    "    \n",
    "    #Step 1: COASTAL PROPERTIES \n",
    "    #to reduce the data size, all non-coastal counties are removed per reference [1] and only  Note for this analysis,\n",
    "    #only contiguous US territories are considered; Hawaii, Puerto Rico, US Virgin Islands and other such territories\n",
    "    #are not included in the analysis. Additionally, counties with great lakes coasts are not considerd since the focus\n",
    "    #is on sea level rising. \n",
    "    fema = fema[fema.STCOFIPS.isin(ccounties.state_county_FIPS)]\n",
    "    \n",
    "    \n",
    "    #Step 2: FEMA FLOOD RISK \n",
    "    ##The risk rating options are 'Not Applicable', 'Very Low', 'No Rating', 'Relatively Low', 'Relatively Moderate', \n",
    "    ##'Very High', 'Relatively High','Insufficient Data'. For the purpose of this analysis, we only keep those \n",
    "    ##locations where the coastal flooding risk is 'Very High', 'Relatively High' and 'Relatively Moderate'\n",
    "    ##See data dictionary for a full list of attribute meanings\n",
    "    \n",
    "    fema = fema[fema.CFLD_RISKR.isin(['Very High', 'Relatively High'])]\n",
    "    \n",
    "    ##create unique_identifier\n",
    "    fema[\"census_tract\"] = fema.STCOFIPS + fema.TRACT\n",
    "    \n",
    "    filename = 'cleaned_FEMA'\n",
    "    compression_options = dict(method='zip', archive_name=f'data/{filename}.pkl')\n",
    "    fema.to_pickle(f'data/{filename}.zip', compression=compression_options)\n",
    "    \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3b4a1c5-7734-4f1c-815a-f89a6426fe5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fema_datacleaning(ccounties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7225febd-014f-45b1-ab6b-396ad1b7793b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
